{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646a0a93",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "In this homework assignment, you will tackle three distinct tasks involving text analysis:\n",
    "\n",
    "1. Tweet Classification: Predict whether a specific tweet pertains to a natural disaster.\n",
    "2. Bank Q&A Analysis: Deduce the user's query based on the text provided.\n",
    "3. Fake News Classification: Determine whether a piece of news is true or false.\n",
    "\n",
    "For educational reasons, we have retained all utility cells for data downloads. However, you can find everything you need in the corresponding GitHub repository subfolder.\n",
    "\n",
    "# Solution Approach\n",
    "\n",
    "Our solution approach will remain relatively consistent for all tasks:\n",
    "\n",
    "1. Encode the text using a certain Language Model (LM), transforming each piece of text into a vector.\n",
    "2. Implement a standard classification model (such as Logistic Regression, Random Forest, etc.) using these features.\n",
    "\n",
    "Despite the varied nature of these tasks, you'll find that this approach provides a solid baseline solution for all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57dd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42985db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip nlp-getting-started.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb41541",
   "metadata": {},
   "source": [
    "# Task 1. Tweets\n",
    "\n",
    "https://www.kaggle.com/competitions/nlp-getting-started\n",
    "\n",
    "\n",
    "1. What is this dataset about?\n",
    "2. Encode text with LM, what is the dimensionality of the resulting embeddings?\n",
    "3. Plot TSNE describe the graph (run TSNE on 128 PCA components).\n",
    "4. Run LR, use 5 fold cross-validation, which metrics are appropriate for this task?\n",
    "5. Comment on model performance\n",
    "6. Explore the results (use out-of-fold predictions), find 3 False Positive tweets, which do not really look like a disaster, e.g.:\n",
    "- https://twitter.com/shauniefish/status/649148030290006017 `I just checked in! \\x89ÛÒ at On Fire on @ZomatoAUS #LoveFood http://t.co/9l5kqykrbG`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d9f29",
   "metadata": {},
   "source": [
    "## 1.1 What is this dataset about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ca8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/tweets/train.csv', index_col=0) # Use direct link to the github file if you are working in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b5377",
   "metadata": {},
   "source": [
    "## 1.2 Encode text with LM, what is the dimensionality of the resulting embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080dc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf80edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d04a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "tweets_embeddings = []\n",
    "\n",
    "for _, tweet in tqdm(df.iterrows()):\n",
    "    vec = embeddings.embed_query(tweet.text)\n",
    "    tweets_embeddings.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c201ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032483d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97e95208",
   "metadata": {},
   "source": [
    "## 1.3 Plot TSNE describe the graph (run TSNE on 128 PCA components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86500ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openTSNE import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "pca = PCA(128)\n",
    "X_pca = ...\n",
    "tsne_embedding = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2fd8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb7758bc",
   "metadata": {},
   "source": [
    "## 1.4 Run LR, use 5 fold cross-validation, which metrics are appropriate for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31d546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c836f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbae58b5",
   "metadata": {},
   "source": [
    "## 1.5 Comment on model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9626276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dff688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9582b36f",
   "metadata": {},
   "source": [
    "## 1.6     Explore the results (use out-of-fold predictions), find 3 False Positive tweets, which do not really look like a disaster, e.g.:\n",
    "\n",
    "    https://twitter.com/shauniefish/status/649148030290006017 I just checked in! \\x89ÛÒ at On Fire on @ZomatoAUS #LoveFood http://t.co/9l5kqykrbG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf14b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (true, prediction) in enumerate(zip(df.target, y_pred)):\n",
    "    if true != prediction:\n",
    "        print(true)\n",
    "        print(prediction)\n",
    "        print(df.iloc[i].text)\n",
    "        print('======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9c067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5b84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "377491ae",
   "metadata": {},
   "source": [
    "# Task 2. Bank Customers' Q&A system\n",
    "\n",
    "https://huggingface.co/datasets/PolyAI/banking77\n",
    "\n",
    "\n",
    "1. What is this dataset about?\n",
    "2. What is the minimal and maximal median text length for different classes (e.g. median text length for `atm_support` is 35).\n",
    "3. Encode text with LM\n",
    "4. Run RF, use 5 fold cross-validation, which metrics are appropriate for this task?\n",
    "5. Comment on model performance\n",
    "6. Analyze the errors of your model (use out-of-fold predictions), which two classes are mostly confused by your model?\n",
    "7. (optional) plot a TSNE graph, with all observations, but color only two classes from the previous question. Make other points  color ligth gray, comment on the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c336b",
   "metadata": {},
   "source": [
    "## 2.1 What is this dataset about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b377e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd02e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06628472",
   "metadata": {},
   "source": [
    "## 2.2 What is the minimal and maximal median text length for different classes?\n",
    "e.g. median text length for atm_support is 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114ccab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685ed27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd6635d",
   "metadata": {},
   "source": [
    "## 2.3 Encode text with LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44022498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbaa621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9913e9e4",
   "metadata": {},
   "source": [
    "## 2.4 Run RF, use 5 fold cross-validation, which metrics are appropriate for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ac804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "clf = RandomForestClassifier(10)\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad536b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2255576",
   "metadata": {},
   "source": [
    "## 2.5 Comment on model performance\n",
    "\n",
    "How many classes in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed46d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd80ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f97ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80f3ab5",
   "metadata": {},
   "source": [
    "## 2.6 Analyze the errors of your model (use out-of-fold predictions). Which two classes are confused by your model the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = dict()\n",
    "\n",
    "for i,(true,predicted) in enumerate(zip(df.category, y_pred)):\n",
    "    if true!=predicted:\n",
    "        key = '-'.join(sorted([true,predicted]))\n",
    "        if key in errors:\n",
    "            errors[key] += 1\n",
    "        else:\n",
    "            errors[key] = 1\n",
    "        print(true)\n",
    "        print(predicted)\n",
    "        print(df.iloc[i].text)\n",
    "        print('======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55579f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(errors.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254bb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7be85214",
   "metadata": {},
   "source": [
    "## 2.7 (optional) plot a TSNE graph, with all observations, but color only two classes from the previous question. Make other points color ligth gray, comment on the graph. Analyze model's errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e3287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8fde57",
   "metadata": {},
   "source": [
    "# Task 3. Fake news\n",
    "\n",
    "https://www.kaggle.com/datasets/jainpooja/fake-news-detection\n",
    "\n",
    "1. What is this dataset about?\n",
    "2. How many unique subjects are in True news and Fake news?\n",
    "3. Encode text with LM\n",
    "4. Run LR, use 5 fold cross-validation, which metrics are appropriate for this task?\n",
    "5. Comment on model performance, would you prefer a model with high Recall or with high Precision?\n",
    "6. (optional) Analyze class distribution of the model. How many articles mentioning \"Trump\" are Fake? How many articles not mentioning \"Trump\" are Fake? Same question for \"Obama\". Can you say that this dataset is biased, explain?\n",
    "7. (optional) using your model find False Positives which are actually True statements (news).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d jainpooja/fake-news-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3747a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip fake-news-detection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba66d06",
   "metadata": {},
   "source": [
    "## 3.1 What is this dataset about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50807266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('./data/fake-news/Fake.csv') # Use direct link to the github file if you are working in colab\n",
    "df_true = pd.read_csv('./data/fake-news/True.csv')\n",
    "df = pd.concat([df_fake, df_true])\n",
    "df['target'] = [1]*df_fake.shape[0]+[0]*df_true.shape[0] # 1 if Fake, 0 o/w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6837f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c065d26",
   "metadata": {},
   "source": [
    "## 3.2 How many unique subjects are in True news and Fake news?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acab2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1fd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "762d61c1",
   "metadata": {},
   "source": [
    "## 3.3 Encode text with LM. \n",
    "\n",
    "due to dataset size it will take ~15 mins on average PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b1048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d9e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d23954c",
   "metadata": {},
   "source": [
    "## 3.4 Run LR, use 5 fold cross-validation, which metrics are appropriate for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068a57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41727c98",
   "metadata": {},
   "source": [
    "## 3.5 Comment on model performance, would you prefer a model with high Recall or with high Precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6158e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029a5596",
   "metadata": {},
   "source": [
    "## 3.6 (optional) Analyze class distribution of the model. \n",
    "\n",
    "How many articles mentioning \"Trump\" are Fake? How many articles not mentioning \"Trump\" are Fake? Same question for \"Obama\". Can you say that this dataset is biased? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_trump'] = df['text'].apply(lambda x: 'Trump' in x)\n",
    "df['is_obama'] = df['text'].apply(lambda x: 'Obama' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217563be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "318fde44",
   "metadata": {},
   "source": [
    "## 3.7 (optional) using your model find False Positives (news which have target \"Fake\" but are actually True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a0c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4fffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
